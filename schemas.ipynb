{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f5b9a06-9b9f-4b84-a1cc-e050e4c7a6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import findspark\n",
    "findspark.init(\"/opt/spark\")\n",
    "from pyspark.sql.functions import explode, from_json, explode_outer\n",
    "from pyspark.sql.functions import col, max, min\n",
    "from pyspark.sql.types import *\n",
    "from delta.tables import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ece8f111-927c-4c34-9875-5fa1c56c7d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring non-Spark config property: fs.s3a.endpoint\n",
      "Warning: Ignoring non-Spark config property: fs.s3a.access.key\n",
      "Warning: Ignoring non-Spark config property: fs.s3a.impl\n",
      "Warning: Ignoring non-Spark config property: fs.s3a.path.style.access\n",
      "Warning: Ignoring non-Spark config property: fs.s3a.secret.key\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      "io.delta#delta-core_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-b1799de2-368f-4659-b0dd-ce1ad367a4e1;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.2.0 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.375 in central\n",
      "\tfound io.delta#delta-core_2.12;2.4.0 in central\n",
      "\tfound io.delta#delta-storage;2.4.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.9.3 in central\n",
      ":: resolution report :: resolve 409ms :: artifacts dl 10ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.375 from central in [default]\n",
      "\tio.delta#delta-core_2.12;2.4.0 from central in [default]\n",
      "\tio.delta#delta-storage;2.4.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.9.3 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.2.0 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   5   |   0   |   0   |   0   ||   5   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-b1799de2-368f-4659-b0dd-ce1ad367a4e1\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 5 already retrieved (0kB/5ms)\n",
      "24/03/23 04:47:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "accessKeyId='dataops9'\n",
    "secretAccessKey='Ankara06'\n",
    "\n",
    "# create a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    ".appName(\"schemas\") \\\n",
    ".master(\"local[2]\") \\\n",
    ".config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:3.2.0,io.delta:delta-core_2.12:2.4.0\") \\\n",
    ".config(\"fs.s3a.access.key\", accessKeyId) \\\n",
    ".config(\"fs.s3a.secret.key\", secretAccessKey) \\\n",
    ".config(\"fs.s3a.path.style.access\", True) \\\n",
    ".config(\"fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    ".config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\\\n",
    ".config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\\\n",
    ".config(\"fs.s3a.endpoint\", \"http://minio:9000\") \\\n",
    ".config(\"spark.sql.debug.maxToStringFields\", 1000) \\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2387799e-9a77-48c3-b26b-66c4accea927",
   "metadata": {},
   "source": [
    "1.cast tablosu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2596f63c-92fc-48c0-b82a-05e95bee0e18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/23 04:47:36 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "cast_schema = StructType([\n",
    "    StructField(\"movie_id\", StringType(), nullable=True),\n",
    "    StructField(\"title\", StringType(), nullable=True),\n",
    "    StructField(\"cast_id\", IntegerType(), nullable=True),\n",
    "    StructField(\"character\", StringType(), nullable=True),\n",
    "    StructField(\"credit_id\", StringType(), nullable=True),\n",
    "    StructField(\"gender\", IntegerType(), nullable=True),\n",
    "    StructField(\"id\", IntegerType(), nullable=True),\n",
    "    StructField(\"name\", StringType(), nullable=True)\n",
    "])\n",
    "\n",
    "cast_table = spark.createDataFrame([], cast_schema)\n",
    "cast_table.write.format(\"delta\").mode(\"overwrite\").save('s3a://tmdb-silver/credits_cast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a83b3c-b5e3-42db-92cb-b403da780061",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eca4ba25-ce04-4560-8063-57080225dd78",
   "metadata": {},
   "source": [
    "2.crew tablosu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1a837b9-cde2-47bc-a006-c05636c904b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "crew_schema = StructType([\n",
    "    StructField(\"movie_id\", StringType(), nullable=True),\n",
    "    StructField(\"title\", StringType(), nullable=True),\n",
    "    StructField(\"credit_id\", StringType(), nullable=True),\n",
    "    StructField(\"department\", StringType(), nullable=True),\n",
    "    StructField(\"gender\", IntegerType(), nullable=True),\n",
    "    StructField(\"id\", IntegerType(), nullable=True),\n",
    "    StructField(\"job\", StringType(), nullable=True),\n",
    "    StructField(\"name\", StringType(), nullable=True)\n",
    "])\n",
    "\n",
    "crew_table = spark.createDataFrame([], crew_schema)\n",
    "crew_table.write.format(\"delta\").mode(\"overwrite\").save('s3a://tmdb-silver/credits_crew')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b5c9d4-04be-4ffb-bddd-02ca967031f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c82c5477-4cdf-4096-aff0-37bfc83392a7",
   "metadata": {},
   "source": [
    "3.movies tablosu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fef5e41b-cc14-4449-8ab2-5d094a22c9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "movies_schema = StructType([\n",
    "    StructField(\"movie_id\", StringType(), nullable=True),\n",
    "    StructField(\"title\", StringType(), nullable=True),\n",
    "    StructField(\"budget\", DoubleType(), nullable=True),\n",
    "    StructField(\"homepage\", StringType(), nullable=True),\n",
    "    StructField(\"original_language\", StringType(), nullable=True),\n",
    "    StructField(\"original_title\", StringType(), nullable=True),\n",
    "    StructField(\"overview\", StringType(), nullable=True),\n",
    "    StructField(\"popularity\", FloatType(), nullable=True),\n",
    "    StructField(\"release_date\", DateType(), nullable=True),\n",
    "    StructField(\"revenue\", DoubleType(), nullable=True),\n",
    "    StructField(\"runtime\", IntegerType(), nullable=True),\n",
    "    StructField(\"status\", StringType(), nullable=True),\n",
    "    StructField(\"tagline\", StringType(), nullable=True),\n",
    "    StructField(\"vote_average\", FloatType(), nullable=True),\n",
    "    StructField(\"vote_count\", IntegerType(), nullable=True)\n",
    "])\n",
    "\n",
    "movies_table = spark.createDataFrame([], movies_schema)\n",
    "movies_table.write.format(\"delta\").mode(\"overwrite\").save('s3a://tmdb-silver/movies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b60932a-f95c-4b1c-aca4-de410015d22b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d385b3e-cfd8-4d04-9659-0254cb3ee95e",
   "metadata": {},
   "source": [
    "4.genres tablosu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f08383cd-821d-4a41-8e11-92550554fe64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "genres_schema = StructType([\n",
    "    StructField(\"movie_id\", StringType(), nullable=True),\n",
    "    StructField(\"id\", IntegerType(), nullable=True),\n",
    "    StructField(\"name\", StringType(), nullable=True)\n",
    "])\n",
    "\n",
    "genres_table = spark.createDataFrame([], genres_schema)\n",
    "genres_table.write.format(\"delta\").mode(\"overwrite\").save('s3a://tmdb-silver/genres')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e394191-990e-4243-92c0-d294aa9ba6c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32667cb0-1e25-4100-8d42-068168424265",
   "metadata": {},
   "source": [
    "5.keywords tablosu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e7f7b37-2f38-445a-b4fc-504a8307553f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "keywords_schema = StructType([\n",
    "    StructField(\"movie_id\", StringType(), nullable=True),\n",
    "    StructField(\"id\", IntegerType(), nullable=True),\n",
    "    StructField(\"name\", StringType(), nullable=True)\n",
    "])\n",
    "keywords_table = spark.createDataFrame([], keywords_schema)\n",
    "keywords_table.write.format(\"delta\").mode(\"overwrite\").save('s3a://tmdb-silver/keywords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cc6052-9914-4e4e-8740-c19d596f0174",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ada3c7f-94ef-4bbf-b08e-4ffe5242d336",
   "metadata": {},
   "source": [
    "6.production_companies tablosu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d36d7648-2c8e-4f41-8473-3b7297ee7c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "production_companies_schema = StructType([\n",
    "    StructField(\"movie_id\", StringType(), nullable=True),\n",
    "    StructField(\"id\", IntegerType(), nullable=True),\n",
    "    StructField(\"name\", StringType(), nullable=True)\n",
    "])\n",
    "production_companies_table = spark.createDataFrame([], production_companies_schema)\n",
    "production_companies_table.write.format(\"delta\").mode(\"overwrite\").save('s3a://tmdb-silver/production_companies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c696bf-17e0-4de2-b155-6e411d951637",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6755fccb-86a5-4a2e-9e1a-ddf97f33905b",
   "metadata": {},
   "source": [
    "7.production_countries tablosu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc76ad7b-cb2e-478d-b570-7afa6edaa347",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "production_countries_schema = StructType([\n",
    "    StructField(\"movie_id\", StringType(), nullable=True),\n",
    "    StructField(\"iso_3166_1\", StringType(), nullable=True),\n",
    "    StructField(\"name\", StringType(), nullable=True)\n",
    "])\n",
    "production_countries_table = spark.createDataFrame([], production_countries_schema)\n",
    "production_countries_table.write.format(\"delta\").mode(\"overwrite\").save('s3a://tmdb-silver/production_countries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39309b0b-b629-4a74-9d5d-6f448e3296a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b6664c7-dc83-4d0c-8a21-445af8eeabe1",
   "metadata": {},
   "source": [
    "8.spoken_languages tablosu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "355ee9cb-3b17-4574-bdcd-a255583bb3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/23 08:45:58 WARN NettyRpcEnv: Ignored failure: java.util.concurrent.TimeoutException: Cannot receive any reply from cc0b8b1f1e73:35534 in 10000 milliseconds\n"
     ]
    }
   ],
   "source": [
    "spoken_languages_schema = StructType([\n",
    "    StructField(\"movie_id\", StringType(), nullable=True),\n",
    "    StructField(\"iso_639_1\", StringType(), nullable=True),\n",
    "    StructField(\"name\", StringType(), nullable=True)\n",
    "])\n",
    "spoken_languages_table = spark.createDataFrame([], spoken_languages_schema)\n",
    "spoken_languages_table.write.format(\"delta\").mode(\"overwrite\").save('s3a://tmdb-silver/spoken_languages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9225cb48-2d9c-45b2-bc7e-3680acf281e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
